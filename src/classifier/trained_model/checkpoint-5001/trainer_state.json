{
  "best_metric": 0.6237752449510098,
  "best_model_checkpoint": "./trained_model/checkpoint-5001",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 5001,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.001999600079984003,
      "grad_norm": 8.486483573913574,
      "learning_rate": 4.9966673332000266e-05,
      "loss": 2.29,
      "step": 10
    },
    {
      "epoch": 0.003999200159968006,
      "grad_norm": 23.02979850769043,
      "learning_rate": 4.9933346664000536e-05,
      "loss": 2.3425,
      "step": 20
    },
    {
      "epoch": 0.00599880023995201,
      "grad_norm": 8.020190238952637,
      "learning_rate": 4.99000199960008e-05,
      "loss": 2.3202,
      "step": 30
    },
    {
      "epoch": 0.007998400319936013,
      "grad_norm": 6.065441608428955,
      "learning_rate": 4.986669332800107e-05,
      "loss": 2.2276,
      "step": 40
    },
    {
      "epoch": 0.009998000399920015,
      "grad_norm": 6.884082794189453,
      "learning_rate": 4.9833366660001333e-05,
      "loss": 2.2507,
      "step": 50
    },
    {
      "epoch": 0.01199760047990402,
      "grad_norm": 7.542108058929443,
      "learning_rate": 4.9800039992001604e-05,
      "loss": 2.2436,
      "step": 60
    },
    {
      "epoch": 0.013997200559888023,
      "grad_norm": 8.273296356201172,
      "learning_rate": 4.976671332400187e-05,
      "loss": 2.2028,
      "step": 70
    },
    {
      "epoch": 0.015996800639872025,
      "grad_norm": 7.5410661697387695,
      "learning_rate": 4.973338665600214e-05,
      "loss": 2.2457,
      "step": 80
    },
    {
      "epoch": 0.017996400719856028,
      "grad_norm": 6.637073040008545,
      "learning_rate": 4.97000599880024e-05,
      "loss": 2.1048,
      "step": 90
    },
    {
      "epoch": 0.01999600079984003,
      "grad_norm": 7.577936172485352,
      "learning_rate": 4.9666733320002665e-05,
      "loss": 2.1358,
      "step": 100
    },
    {
      "epoch": 0.021995600879824034,
      "grad_norm": 6.453656196594238,
      "learning_rate": 4.9633406652002935e-05,
      "loss": 2.1912,
      "step": 110
    },
    {
      "epoch": 0.02399520095980804,
      "grad_norm": 7.3829121589660645,
      "learning_rate": 4.96000799840032e-05,
      "loss": 2.1957,
      "step": 120
    },
    {
      "epoch": 0.025994801039792043,
      "grad_norm": 8.003046035766602,
      "learning_rate": 4.956675331600347e-05,
      "loss": 2.1056,
      "step": 130
    },
    {
      "epoch": 0.027994401119776045,
      "grad_norm": 6.657829284667969,
      "learning_rate": 4.953342664800373e-05,
      "loss": 2.1079,
      "step": 140
    },
    {
      "epoch": 0.029994001199760048,
      "grad_norm": 6.863305568695068,
      "learning_rate": 4.9500099980004e-05,
      "loss": 2.0691,
      "step": 150
    },
    {
      "epoch": 0.03199360127974405,
      "grad_norm": 7.502652168273926,
      "learning_rate": 4.9466773312004266e-05,
      "loss": 2.0581,
      "step": 160
    },
    {
      "epoch": 0.033993201359728054,
      "grad_norm": 6.225324630737305,
      "learning_rate": 4.9433446644004536e-05,
      "loss": 2.0105,
      "step": 170
    },
    {
      "epoch": 0.035992801439712056,
      "grad_norm": 7.140869140625,
      "learning_rate": 4.94001199760048e-05,
      "loss": 1.9497,
      "step": 180
    },
    {
      "epoch": 0.03799240151969606,
      "grad_norm": 7.257124423980713,
      "learning_rate": 4.936679330800506e-05,
      "loss": 2.0594,
      "step": 190
    },
    {
      "epoch": 0.03999200159968006,
      "grad_norm": 8.895133018493652,
      "learning_rate": 4.9333466640005333e-05,
      "loss": 1.9021,
      "step": 200
    },
    {
      "epoch": 0.041991601679664065,
      "grad_norm": 8.184698104858398,
      "learning_rate": 4.93001399720056e-05,
      "loss": 2.0463,
      "step": 210
    },
    {
      "epoch": 0.04399120175964807,
      "grad_norm": 7.4633002281188965,
      "learning_rate": 4.926681330400587e-05,
      "loss": 1.8619,
      "step": 220
    },
    {
      "epoch": 0.04599080183963208,
      "grad_norm": 10.627445220947266,
      "learning_rate": 4.923348663600613e-05,
      "loss": 1.9402,
      "step": 230
    },
    {
      "epoch": 0.04799040191961608,
      "grad_norm": 6.723014831542969,
      "learning_rate": 4.92001599680064e-05,
      "loss": 1.8906,
      "step": 240
    },
    {
      "epoch": 0.04999000199960008,
      "grad_norm": 8.850643157958984,
      "learning_rate": 4.9166833300006664e-05,
      "loss": 1.9113,
      "step": 250
    },
    {
      "epoch": 0.051989602079584085,
      "grad_norm": 7.870445251464844,
      "learning_rate": 4.9133506632006935e-05,
      "loss": 1.9412,
      "step": 260
    },
    {
      "epoch": 0.05398920215956809,
      "grad_norm": 7.138870716094971,
      "learning_rate": 4.9100179964007205e-05,
      "loss": 1.9972,
      "step": 270
    },
    {
      "epoch": 0.05598880223955209,
      "grad_norm": 10.539412498474121,
      "learning_rate": 4.906685329600747e-05,
      "loss": 1.9351,
      "step": 280
    },
    {
      "epoch": 0.05798840231953609,
      "grad_norm": 13.7241792678833,
      "learning_rate": 4.903352662800774e-05,
      "loss": 1.8579,
      "step": 290
    },
    {
      "epoch": 0.059988002399520096,
      "grad_norm": 6.764505863189697,
      "learning_rate": 4.9000199960008e-05,
      "loss": 1.7772,
      "step": 300
    },
    {
      "epoch": 0.0619876024795041,
      "grad_norm": 8.268332481384277,
      "learning_rate": 4.896687329200827e-05,
      "loss": 1.8775,
      "step": 310
    },
    {
      "epoch": 0.0639872025594881,
      "grad_norm": 9.532472610473633,
      "learning_rate": 4.8933546624008536e-05,
      "loss": 1.8566,
      "step": 320
    },
    {
      "epoch": 0.06598680263947211,
      "grad_norm": 9.410441398620605,
      "learning_rate": 4.89002199560088e-05,
      "loss": 1.7573,
      "step": 330
    },
    {
      "epoch": 0.06798640271945611,
      "grad_norm": 8.815823554992676,
      "learning_rate": 4.886689328800907e-05,
      "loss": 1.8349,
      "step": 340
    },
    {
      "epoch": 0.06998600279944012,
      "grad_norm": 10.014233589172363,
      "learning_rate": 4.8833566620009333e-05,
      "loss": 1.7115,
      "step": 350
    },
    {
      "epoch": 0.07198560287942411,
      "grad_norm": 7.97587776184082,
      "learning_rate": 4.8800239952009604e-05,
      "loss": 1.7167,
      "step": 360
    },
    {
      "epoch": 0.07398520295940812,
      "grad_norm": 10.347760200500488,
      "learning_rate": 4.876691328400987e-05,
      "loss": 1.9247,
      "step": 370
    },
    {
      "epoch": 0.07598480303939212,
      "grad_norm": 9.23169231414795,
      "learning_rate": 4.873358661601014e-05,
      "loss": 1.6842,
      "step": 380
    },
    {
      "epoch": 0.07798440311937613,
      "grad_norm": 8.449100494384766,
      "learning_rate": 4.87002599480104e-05,
      "loss": 1.6756,
      "step": 390
    },
    {
      "epoch": 0.07998400319936012,
      "grad_norm": 6.70433235168457,
      "learning_rate": 4.866693328001067e-05,
      "loss": 1.4329,
      "step": 400
    },
    {
      "epoch": 0.08198360327934413,
      "grad_norm": 9.499358177185059,
      "learning_rate": 4.8633606612010935e-05,
      "loss": 1.9025,
      "step": 410
    },
    {
      "epoch": 0.08398320335932813,
      "grad_norm": 9.831555366516113,
      "learning_rate": 4.86002799440112e-05,
      "loss": 1.8554,
      "step": 420
    },
    {
      "epoch": 0.08598280343931214,
      "grad_norm": 8.456974983215332,
      "learning_rate": 4.856695327601147e-05,
      "loss": 1.6412,
      "step": 430
    },
    {
      "epoch": 0.08798240351929613,
      "grad_norm": 6.636467933654785,
      "learning_rate": 4.853362660801173e-05,
      "loss": 1.5953,
      "step": 440
    },
    {
      "epoch": 0.08998200359928014,
      "grad_norm": 14.0305757522583,
      "learning_rate": 4.8500299940012e-05,
      "loss": 1.4538,
      "step": 450
    },
    {
      "epoch": 0.09198160367926415,
      "grad_norm": 10.056876182556152,
      "learning_rate": 4.8466973272012266e-05,
      "loss": 1.6688,
      "step": 460
    },
    {
      "epoch": 0.09398120375924815,
      "grad_norm": 11.251740455627441,
      "learning_rate": 4.8433646604012536e-05,
      "loss": 1.6104,
      "step": 470
    },
    {
      "epoch": 0.09598080383923216,
      "grad_norm": 11.618427276611328,
      "learning_rate": 4.84003199360128e-05,
      "loss": 1.6278,
      "step": 480
    },
    {
      "epoch": 0.09798040391921616,
      "grad_norm": 11.514531135559082,
      "learning_rate": 4.836699326801307e-05,
      "loss": 1.525,
      "step": 490
    },
    {
      "epoch": 0.09998000399920016,
      "grad_norm": 12.38217830657959,
      "learning_rate": 4.833366660001333e-05,
      "loss": 1.7233,
      "step": 500
    },
    {
      "epoch": 0.10197960407918416,
      "grad_norm": 9.643281936645508,
      "learning_rate": 4.83003399320136e-05,
      "loss": 1.5336,
      "step": 510
    },
    {
      "epoch": 0.10397920415916817,
      "grad_norm": 9.240829467773438,
      "learning_rate": 4.826701326401387e-05,
      "loss": 1.497,
      "step": 520
    },
    {
      "epoch": 0.10597880423915217,
      "grad_norm": 11.246994972229004,
      "learning_rate": 4.823368659601413e-05,
      "loss": 1.5234,
      "step": 530
    },
    {
      "epoch": 0.10797840431913618,
      "grad_norm": 10.207000732421875,
      "learning_rate": 4.82003599280144e-05,
      "loss": 1.9054,
      "step": 540
    },
    {
      "epoch": 0.10997800439912017,
      "grad_norm": 14.543898582458496,
      "learning_rate": 4.8167033260014664e-05,
      "loss": 1.5054,
      "step": 550
    },
    {
      "epoch": 0.11197760447910418,
      "grad_norm": 8.36032485961914,
      "learning_rate": 4.8133706592014935e-05,
      "loss": 1.5388,
      "step": 560
    },
    {
      "epoch": 0.11397720455908818,
      "grad_norm": 13.23294448852539,
      "learning_rate": 4.81003799240152e-05,
      "loss": 1.5393,
      "step": 570
    },
    {
      "epoch": 0.11597680463907219,
      "grad_norm": 9.620367050170898,
      "learning_rate": 4.806705325601547e-05,
      "loss": 1.4854,
      "step": 580
    },
    {
      "epoch": 0.11797640471905618,
      "grad_norm": 11.607989311218262,
      "learning_rate": 4.803372658801573e-05,
      "loss": 1.8466,
      "step": 590
    },
    {
      "epoch": 0.11997600479904019,
      "grad_norm": 9.428267478942871,
      "learning_rate": 4.8000399920015995e-05,
      "loss": 1.4937,
      "step": 600
    },
    {
      "epoch": 0.1219756048790242,
      "grad_norm": 9.171460151672363,
      "learning_rate": 4.7967073252016266e-05,
      "loss": 1.6304,
      "step": 610
    },
    {
      "epoch": 0.1239752049590082,
      "grad_norm": 11.798443794250488,
      "learning_rate": 4.793374658401653e-05,
      "loss": 1.4827,
      "step": 620
    },
    {
      "epoch": 0.1259748050389922,
      "grad_norm": 8.675115585327148,
      "learning_rate": 4.79004199160168e-05,
      "loss": 1.6025,
      "step": 630
    },
    {
      "epoch": 0.1279744051189762,
      "grad_norm": 18.90923500061035,
      "learning_rate": 4.786709324801706e-05,
      "loss": 1.6164,
      "step": 640
    },
    {
      "epoch": 0.1299740051989602,
      "grad_norm": 10.327335357666016,
      "learning_rate": 4.783376658001733e-05,
      "loss": 1.4738,
      "step": 650
    },
    {
      "epoch": 0.13197360527894422,
      "grad_norm": 7.653177738189697,
      "learning_rate": 4.78004399120176e-05,
      "loss": 1.5338,
      "step": 660
    },
    {
      "epoch": 0.1339732053589282,
      "grad_norm": 12.2083740234375,
      "learning_rate": 4.776711324401786e-05,
      "loss": 1.5009,
      "step": 670
    },
    {
      "epoch": 0.13597280543891221,
      "grad_norm": 9.088950157165527,
      "learning_rate": 4.773378657601813e-05,
      "loss": 1.4126,
      "step": 680
    },
    {
      "epoch": 0.13797240551889622,
      "grad_norm": 10.023622512817383,
      "learning_rate": 4.7700459908018394e-05,
      "loss": 1.8376,
      "step": 690
    },
    {
      "epoch": 0.13997200559888023,
      "grad_norm": 12.354560852050781,
      "learning_rate": 4.7667133240018664e-05,
      "loss": 1.3388,
      "step": 700
    },
    {
      "epoch": 0.14197160567886422,
      "grad_norm": 10.93286418914795,
      "learning_rate": 4.763380657201893e-05,
      "loss": 1.5739,
      "step": 710
    },
    {
      "epoch": 0.14397120575884823,
      "grad_norm": 7.3670477867126465,
      "learning_rate": 4.76004799040192e-05,
      "loss": 1.6356,
      "step": 720
    },
    {
      "epoch": 0.14597080583883223,
      "grad_norm": 11.679475784301758,
      "learning_rate": 4.756715323601946e-05,
      "loss": 1.48,
      "step": 730
    },
    {
      "epoch": 0.14797040591881624,
      "grad_norm": 10.872512817382812,
      "learning_rate": 4.753382656801973e-05,
      "loss": 1.7101,
      "step": 740
    },
    {
      "epoch": 0.14997000599880023,
      "grad_norm": 8.5926513671875,
      "learning_rate": 4.7500499900019995e-05,
      "loss": 1.4482,
      "step": 750
    },
    {
      "epoch": 0.15196960607878424,
      "grad_norm": 15.137410163879395,
      "learning_rate": 4.746717323202026e-05,
      "loss": 1.6292,
      "step": 760
    },
    {
      "epoch": 0.15396920615876825,
      "grad_norm": 7.711568832397461,
      "learning_rate": 4.743384656402053e-05,
      "loss": 1.596,
      "step": 770
    },
    {
      "epoch": 0.15596880623875226,
      "grad_norm": 8.692476272583008,
      "learning_rate": 4.74005198960208e-05,
      "loss": 1.6412,
      "step": 780
    },
    {
      "epoch": 0.15796840631873627,
      "grad_norm": 11.786295890808105,
      "learning_rate": 4.736719322802107e-05,
      "loss": 1.2785,
      "step": 790
    },
    {
      "epoch": 0.15996800639872025,
      "grad_norm": 13.041200637817383,
      "learning_rate": 4.733386656002133e-05,
      "loss": 1.3944,
      "step": 800
    },
    {
      "epoch": 0.16196760647870426,
      "grad_norm": 9.187958717346191,
      "learning_rate": 4.7300539892021604e-05,
      "loss": 1.5101,
      "step": 810
    },
    {
      "epoch": 0.16396720655868827,
      "grad_norm": 7.86534309387207,
      "learning_rate": 4.726721322402187e-05,
      "loss": 1.4288,
      "step": 820
    },
    {
      "epoch": 0.16596680663867228,
      "grad_norm": 17.428510665893555,
      "learning_rate": 4.723388655602213e-05,
      "loss": 1.3366,
      "step": 830
    },
    {
      "epoch": 0.16796640671865626,
      "grad_norm": 10.72262954711914,
      "learning_rate": 4.72005598880224e-05,
      "loss": 1.4652,
      "step": 840
    },
    {
      "epoch": 0.16996600679864027,
      "grad_norm": 9.7687349319458,
      "learning_rate": 4.7167233220022664e-05,
      "loss": 1.4758,
      "step": 850
    },
    {
      "epoch": 0.17196560687862428,
      "grad_norm": 9.781272888183594,
      "learning_rate": 4.7133906552022935e-05,
      "loss": 1.3669,
      "step": 860
    },
    {
      "epoch": 0.1739652069586083,
      "grad_norm": 13.76578426361084,
      "learning_rate": 4.71005798840232e-05,
      "loss": 1.5577,
      "step": 870
    },
    {
      "epoch": 0.17596480703859227,
      "grad_norm": 6.283199310302734,
      "learning_rate": 4.706725321602347e-05,
      "loss": 1.5136,
      "step": 880
    },
    {
      "epoch": 0.17796440711857628,
      "grad_norm": 7.023477077484131,
      "learning_rate": 4.703392654802373e-05,
      "loss": 1.3839,
      "step": 890
    },
    {
      "epoch": 0.1799640071985603,
      "grad_norm": 10.161480903625488,
      "learning_rate": 4.7000599880024e-05,
      "loss": 1.6868,
      "step": 900
    },
    {
      "epoch": 0.1819636072785443,
      "grad_norm": 12.608484268188477,
      "learning_rate": 4.6967273212024266e-05,
      "loss": 1.6066,
      "step": 910
    },
    {
      "epoch": 0.1839632073585283,
      "grad_norm": 9.216276168823242,
      "learning_rate": 4.693394654402453e-05,
      "loss": 1.7574,
      "step": 920
    },
    {
      "epoch": 0.1859628074385123,
      "grad_norm": 13.055495262145996,
      "learning_rate": 4.69006198760248e-05,
      "loss": 1.584,
      "step": 930
    },
    {
      "epoch": 0.1879624075184963,
      "grad_norm": 14.09416389465332,
      "learning_rate": 4.686729320802506e-05,
      "loss": 1.3843,
      "step": 940
    },
    {
      "epoch": 0.1899620075984803,
      "grad_norm": 7.26009464263916,
      "learning_rate": 4.683396654002533e-05,
      "loss": 1.2144,
      "step": 950
    },
    {
      "epoch": 0.19196160767846432,
      "grad_norm": 7.7341437339782715,
      "learning_rate": 4.68006398720256e-05,
      "loss": 1.3398,
      "step": 960
    },
    {
      "epoch": 0.1939612077584483,
      "grad_norm": 12.265687942504883,
      "learning_rate": 4.676731320402587e-05,
      "loss": 1.6898,
      "step": 970
    },
    {
      "epoch": 0.1959608078384323,
      "grad_norm": 11.596131324768066,
      "learning_rate": 4.673398653602613e-05,
      "loss": 1.5245,
      "step": 980
    },
    {
      "epoch": 0.19796040791841632,
      "grad_norm": 12.545600891113281,
      "learning_rate": 4.6700659868026394e-05,
      "loss": 1.4145,
      "step": 990
    },
    {
      "epoch": 0.19996000799840033,
      "grad_norm": 12.142346382141113,
      "learning_rate": 4.6667333200026664e-05,
      "loss": 1.4091,
      "step": 1000
    },
    {
      "epoch": 0.2019596080783843,
      "grad_norm": 12.169853210449219,
      "learning_rate": 4.663400653202693e-05,
      "loss": 1.5774,
      "step": 1010
    },
    {
      "epoch": 0.20395920815836832,
      "grad_norm": 11.01085376739502,
      "learning_rate": 4.66006798640272e-05,
      "loss": 1.5963,
      "step": 1020
    },
    {
      "epoch": 0.20595880823835233,
      "grad_norm": 9.94249439239502,
      "learning_rate": 4.656735319602746e-05,
      "loss": 1.7998,
      "step": 1030
    },
    {
      "epoch": 0.20795840831833634,
      "grad_norm": 13.21448040008545,
      "learning_rate": 4.653402652802773e-05,
      "loss": 1.5053,
      "step": 1040
    },
    {
      "epoch": 0.20995800839832032,
      "grad_norm": 12.69991683959961,
      "learning_rate": 4.6500699860027995e-05,
      "loss": 1.3867,
      "step": 1050
    },
    {
      "epoch": 0.21195760847830433,
      "grad_norm": 9.030729293823242,
      "learning_rate": 4.6467373192028266e-05,
      "loss": 1.3164,
      "step": 1060
    },
    {
      "epoch": 0.21395720855828834,
      "grad_norm": 9.211381912231445,
      "learning_rate": 4.643404652402853e-05,
      "loss": 1.4043,
      "step": 1070
    },
    {
      "epoch": 0.21595680863827235,
      "grad_norm": 10.702520370483398,
      "learning_rate": 4.640071985602879e-05,
      "loss": 1.3004,
      "step": 1080
    },
    {
      "epoch": 0.21795640871825636,
      "grad_norm": 11.85316276550293,
      "learning_rate": 4.636739318802906e-05,
      "loss": 1.1928,
      "step": 1090
    },
    {
      "epoch": 0.21995600879824034,
      "grad_norm": 9.451969146728516,
      "learning_rate": 4.6334066520029326e-05,
      "loss": 1.6014,
      "step": 1100
    },
    {
      "epoch": 0.22195560887822435,
      "grad_norm": 12.471943855285645,
      "learning_rate": 4.63007398520296e-05,
      "loss": 1.7064,
      "step": 1110
    },
    {
      "epoch": 0.22395520895820836,
      "grad_norm": 8.981622695922852,
      "learning_rate": 4.626741318402986e-05,
      "loss": 1.459,
      "step": 1120
    },
    {
      "epoch": 0.22595480903819237,
      "grad_norm": 8.550056457519531,
      "learning_rate": 4.623408651603013e-05,
      "loss": 1.6949,
      "step": 1130
    },
    {
      "epoch": 0.22795440911817635,
      "grad_norm": 9.892953872680664,
      "learning_rate": 4.6200759848030394e-05,
      "loss": 1.7617,
      "step": 1140
    },
    {
      "epoch": 0.22995400919816036,
      "grad_norm": 8.144174575805664,
      "learning_rate": 4.6167433180030664e-05,
      "loss": 1.4758,
      "step": 1150
    },
    {
      "epoch": 0.23195360927814437,
      "grad_norm": 8.207463264465332,
      "learning_rate": 4.613410651203093e-05,
      "loss": 1.4159,
      "step": 1160
    },
    {
      "epoch": 0.23395320935812838,
      "grad_norm": 10.39710521697998,
      "learning_rate": 4.610077984403119e-05,
      "loss": 1.2303,
      "step": 1170
    },
    {
      "epoch": 0.23595280943811237,
      "grad_norm": 12.242365837097168,
      "learning_rate": 4.606745317603146e-05,
      "loss": 1.6174,
      "step": 1180
    },
    {
      "epoch": 0.23795240951809637,
      "grad_norm": 6.95166540145874,
      "learning_rate": 4.6034126508031725e-05,
      "loss": 1.2082,
      "step": 1190
    },
    {
      "epoch": 0.23995200959808038,
      "grad_norm": 11.375865936279297,
      "learning_rate": 4.6000799840031995e-05,
      "loss": 1.4974,
      "step": 1200
    },
    {
      "epoch": 0.2419516096780644,
      "grad_norm": 11.419027328491211,
      "learning_rate": 4.596747317203226e-05,
      "loss": 1.572,
      "step": 1210
    },
    {
      "epoch": 0.2439512097580484,
      "grad_norm": 10.515029907226562,
      "learning_rate": 4.593414650403253e-05,
      "loss": 1.4316,
      "step": 1220
    },
    {
      "epoch": 0.24595080983803239,
      "grad_norm": 8.428004264831543,
      "learning_rate": 4.590081983603279e-05,
      "loss": 1.3163,
      "step": 1230
    },
    {
      "epoch": 0.2479504099180164,
      "grad_norm": 10.471663475036621,
      "learning_rate": 4.586749316803306e-05,
      "loss": 1.3908,
      "step": 1240
    },
    {
      "epoch": 0.2499500099980004,
      "grad_norm": 10.277301788330078,
      "learning_rate": 4.5834166500033326e-05,
      "loss": 1.5551,
      "step": 1250
    },
    {
      "epoch": 0.2519496100779844,
      "grad_norm": 6.981058597564697,
      "learning_rate": 4.580083983203359e-05,
      "loss": 1.4664,
      "step": 1260
    },
    {
      "epoch": 0.2539492101579684,
      "grad_norm": 12.309026718139648,
      "learning_rate": 4.576751316403386e-05,
      "loss": 1.3181,
      "step": 1270
    },
    {
      "epoch": 0.2559488102379524,
      "grad_norm": 12.076576232910156,
      "learning_rate": 4.5734186496034124e-05,
      "loss": 1.5454,
      "step": 1280
    },
    {
      "epoch": 0.2579484103179364,
      "grad_norm": 10.341789245605469,
      "learning_rate": 4.57008598280344e-05,
      "loss": 1.4374,
      "step": 1290
    },
    {
      "epoch": 0.2599480103979204,
      "grad_norm": 8.169737815856934,
      "learning_rate": 4.5667533160034664e-05,
      "loss": 1.3568,
      "step": 1300
    },
    {
      "epoch": 0.26194761047790444,
      "grad_norm": 7.443861961364746,
      "learning_rate": 4.563420649203493e-05,
      "loss": 1.3275,
      "step": 1310
    },
    {
      "epoch": 0.26394721055788845,
      "grad_norm": 10.078680038452148,
      "learning_rate": 4.56008798240352e-05,
      "loss": 1.4387,
      "step": 1320
    },
    {
      "epoch": 0.2659468106378724,
      "grad_norm": 9.901040077209473,
      "learning_rate": 4.556755315603546e-05,
      "loss": 1.0959,
      "step": 1330
    },
    {
      "epoch": 0.2679464107178564,
      "grad_norm": 9.337478637695312,
      "learning_rate": 4.553422648803573e-05,
      "loss": 1.5797,
      "step": 1340
    },
    {
      "epoch": 0.2699460107978404,
      "grad_norm": 16.274538040161133,
      "learning_rate": 4.5500899820035995e-05,
      "loss": 1.1363,
      "step": 1350
    },
    {
      "epoch": 0.27194561087782443,
      "grad_norm": 8.576570510864258,
      "learning_rate": 4.5467573152036266e-05,
      "loss": 1.2673,
      "step": 1360
    },
    {
      "epoch": 0.27394521095780844,
      "grad_norm": 14.18104362487793,
      "learning_rate": 4.543424648403653e-05,
      "loss": 1.3367,
      "step": 1370
    },
    {
      "epoch": 0.27594481103779245,
      "grad_norm": 16.912872314453125,
      "learning_rate": 4.54009198160368e-05,
      "loss": 1.75,
      "step": 1380
    },
    {
      "epoch": 0.27794441111777646,
      "grad_norm": 9.762338638305664,
      "learning_rate": 4.536759314803706e-05,
      "loss": 1.2588,
      "step": 1390
    },
    {
      "epoch": 0.27994401119776047,
      "grad_norm": 8.185384750366211,
      "learning_rate": 4.5334266480037326e-05,
      "loss": 1.4889,
      "step": 1400
    },
    {
      "epoch": 0.2819436112777445,
      "grad_norm": 12.606782913208008,
      "learning_rate": 4.53009398120376e-05,
      "loss": 1.3724,
      "step": 1410
    },
    {
      "epoch": 0.28394321135772843,
      "grad_norm": 7.541880130767822,
      "learning_rate": 4.526761314403786e-05,
      "loss": 1.3016,
      "step": 1420
    },
    {
      "epoch": 0.28594281143771244,
      "grad_norm": 7.293546676635742,
      "learning_rate": 4.523428647603813e-05,
      "loss": 1.2568,
      "step": 1430
    },
    {
      "epoch": 0.28794241151769645,
      "grad_norm": 10.203044891357422,
      "learning_rate": 4.5200959808038394e-05,
      "loss": 1.2787,
      "step": 1440
    },
    {
      "epoch": 0.28994201159768046,
      "grad_norm": 11.306634902954102,
      "learning_rate": 4.5167633140038664e-05,
      "loss": 1.3075,
      "step": 1450
    },
    {
      "epoch": 0.29194161167766447,
      "grad_norm": 11.130594253540039,
      "learning_rate": 4.513430647203893e-05,
      "loss": 1.4412,
      "step": 1460
    },
    {
      "epoch": 0.2939412117576485,
      "grad_norm": 12.61267375946045,
      "learning_rate": 4.51009798040392e-05,
      "loss": 1.4638,
      "step": 1470
    },
    {
      "epoch": 0.2959408118376325,
      "grad_norm": 11.044858932495117,
      "learning_rate": 4.506765313603946e-05,
      "loss": 1.2142,
      "step": 1480
    },
    {
      "epoch": 0.2979404119176165,
      "grad_norm": 10.749207496643066,
      "learning_rate": 4.5034326468039725e-05,
      "loss": 1.2413,
      "step": 1490
    },
    {
      "epoch": 0.29994001199760045,
      "grad_norm": 13.847024917602539,
      "learning_rate": 4.5000999800039995e-05,
      "loss": 1.3353,
      "step": 1500
    },
    {
      "epoch": 0.30193961207758446,
      "grad_norm": 7.468137741088867,
      "learning_rate": 4.496767313204026e-05,
      "loss": 1.2833,
      "step": 1510
    },
    {
      "epoch": 0.3039392121575685,
      "grad_norm": 7.363351821899414,
      "learning_rate": 4.493434646404053e-05,
      "loss": 1.2521,
      "step": 1520
    },
    {
      "epoch": 0.3059388122375525,
      "grad_norm": 11.773109436035156,
      "learning_rate": 4.490101979604079e-05,
      "loss": 1.5557,
      "step": 1530
    },
    {
      "epoch": 0.3079384123175365,
      "grad_norm": 6.45768404006958,
      "learning_rate": 4.486769312804106e-05,
      "loss": 1.1955,
      "step": 1540
    },
    {
      "epoch": 0.3099380123975205,
      "grad_norm": 10.601333618164062,
      "learning_rate": 4.4834366460041326e-05,
      "loss": 1.4657,
      "step": 1550
    },
    {
      "epoch": 0.3119376124775045,
      "grad_norm": 12.380545616149902,
      "learning_rate": 4.4801039792041597e-05,
      "loss": 1.3831,
      "step": 1560
    },
    {
      "epoch": 0.3139372125574885,
      "grad_norm": 9.64351749420166,
      "learning_rate": 4.476771312404186e-05,
      "loss": 1.4464,
      "step": 1570
    },
    {
      "epoch": 0.31593681263747253,
      "grad_norm": 10.940901756286621,
      "learning_rate": 4.4734386456042124e-05,
      "loss": 1.404,
      "step": 1580
    },
    {
      "epoch": 0.3179364127174565,
      "grad_norm": 14.800042152404785,
      "learning_rate": 4.4701059788042394e-05,
      "loss": 1.2978,
      "step": 1590
    },
    {
      "epoch": 0.3199360127974405,
      "grad_norm": 8.449132919311523,
      "learning_rate": 4.466773312004266e-05,
      "loss": 1.526,
      "step": 1600
    },
    {
      "epoch": 0.3219356128774245,
      "grad_norm": 12.05859661102295,
      "learning_rate": 4.463440645204293e-05,
      "loss": 1.314,
      "step": 1610
    },
    {
      "epoch": 0.3239352129574085,
      "grad_norm": 13.708454132080078,
      "learning_rate": 4.460107978404319e-05,
      "loss": 1.4002,
      "step": 1620
    },
    {
      "epoch": 0.3259348130373925,
      "grad_norm": 13.73060131072998,
      "learning_rate": 4.456775311604346e-05,
      "loss": 1.3451,
      "step": 1630
    },
    {
      "epoch": 0.32793441311737653,
      "grad_norm": 12.938565254211426,
      "learning_rate": 4.4534426448043725e-05,
      "loss": 1.55,
      "step": 1640
    },
    {
      "epoch": 0.32993401319736054,
      "grad_norm": 12.568390846252441,
      "learning_rate": 4.4501099780043995e-05,
      "loss": 1.447,
      "step": 1650
    },
    {
      "epoch": 0.33193361327734455,
      "grad_norm": 15.179072380065918,
      "learning_rate": 4.446777311204426e-05,
      "loss": 1.4206,
      "step": 1660
    },
    {
      "epoch": 0.3339332133573285,
      "grad_norm": 10.558350563049316,
      "learning_rate": 4.443444644404452e-05,
      "loss": 1.328,
      "step": 1670
    },
    {
      "epoch": 0.3359328134373125,
      "grad_norm": 7.207569122314453,
      "learning_rate": 4.440111977604479e-05,
      "loss": 1.4097,
      "step": 1680
    },
    {
      "epoch": 0.3379324135172965,
      "grad_norm": 13.435464859008789,
      "learning_rate": 4.4367793108045056e-05,
      "loss": 1.3629,
      "step": 1690
    },
    {
      "epoch": 0.33993201359728054,
      "grad_norm": 10.228316307067871,
      "learning_rate": 4.4334466440045326e-05,
      "loss": 1.3451,
      "step": 1700
    },
    {
      "epoch": 0.34193161367726455,
      "grad_norm": 10.333452224731445,
      "learning_rate": 4.430113977204559e-05,
      "loss": 1.4554,
      "step": 1710
    },
    {
      "epoch": 0.34393121375724856,
      "grad_norm": 7.805350303649902,
      "learning_rate": 4.426781310404586e-05,
      "loss": 1.4457,
      "step": 1720
    },
    {
      "epoch": 0.34593081383723256,
      "grad_norm": 14.084467887878418,
      "learning_rate": 4.4234486436046124e-05,
      "loss": 1.326,
      "step": 1730
    },
    {
      "epoch": 0.3479304139172166,
      "grad_norm": 6.707535266876221,
      "learning_rate": 4.4201159768046394e-05,
      "loss": 1.5048,
      "step": 1740
    },
    {
      "epoch": 0.3499300139972006,
      "grad_norm": 7.939605236053467,
      "learning_rate": 4.416783310004666e-05,
      "loss": 1.1874,
      "step": 1750
    },
    {
      "epoch": 0.35192961407718454,
      "grad_norm": 10.233711242675781,
      "learning_rate": 4.413450643204692e-05,
      "loss": 1.2484,
      "step": 1760
    },
    {
      "epoch": 0.35392921415716855,
      "grad_norm": 15.285201072692871,
      "learning_rate": 4.410117976404719e-05,
      "loss": 1.2695,
      "step": 1770
    },
    {
      "epoch": 0.35592881423715256,
      "grad_norm": 12.951933860778809,
      "learning_rate": 4.4067853096047455e-05,
      "loss": 1.4355,
      "step": 1780
    },
    {
      "epoch": 0.35792841431713657,
      "grad_norm": 15.830033302307129,
      "learning_rate": 4.4034526428047725e-05,
      "loss": 1.4417,
      "step": 1790
    },
    {
      "epoch": 0.3599280143971206,
      "grad_norm": 7.617671489715576,
      "learning_rate": 4.4001199760047995e-05,
      "loss": 1.3658,
      "step": 1800
    },
    {
      "epoch": 0.3619276144771046,
      "grad_norm": 14.878056526184082,
      "learning_rate": 4.396787309204826e-05,
      "loss": 1.2227,
      "step": 1810
    },
    {
      "epoch": 0.3639272145570886,
      "grad_norm": 13.695913314819336,
      "learning_rate": 4.393454642404853e-05,
      "loss": 1.4606,
      "step": 1820
    },
    {
      "epoch": 0.3659268146370726,
      "grad_norm": 12.099872589111328,
      "learning_rate": 4.390121975604879e-05,
      "loss": 1.2938,
      "step": 1830
    },
    {
      "epoch": 0.3679264147170566,
      "grad_norm": 10.036174774169922,
      "learning_rate": 4.386789308804906e-05,
      "loss": 1.3093,
      "step": 1840
    },
    {
      "epoch": 0.36992601479704057,
      "grad_norm": 6.709839820861816,
      "learning_rate": 4.3834566420049326e-05,
      "loss": 1.4853,
      "step": 1850
    },
    {
      "epoch": 0.3719256148770246,
      "grad_norm": 4.925860404968262,
      "learning_rate": 4.3801239752049597e-05,
      "loss": 1.4173,
      "step": 1860
    },
    {
      "epoch": 0.3739252149570086,
      "grad_norm": 11.966093063354492,
      "learning_rate": 4.376791308404986e-05,
      "loss": 1.2895,
      "step": 1870
    },
    {
      "epoch": 0.3759248150369926,
      "grad_norm": 10.420259475708008,
      "learning_rate": 4.373458641605013e-05,
      "loss": 1.3862,
      "step": 1880
    },
    {
      "epoch": 0.3779244151169766,
      "grad_norm": 15.055235862731934,
      "learning_rate": 4.3701259748050394e-05,
      "loss": 1.4851,
      "step": 1890
    },
    {
      "epoch": 0.3799240151969606,
      "grad_norm": 16.069576263427734,
      "learning_rate": 4.366793308005066e-05,
      "loss": 1.4612,
      "step": 1900
    },
    {
      "epoch": 0.38192361527694463,
      "grad_norm": 9.623614311218262,
      "learning_rate": 4.363460641205093e-05,
      "loss": 1.3047,
      "step": 1910
    },
    {
      "epoch": 0.38392321535692864,
      "grad_norm": 6.300931930541992,
      "learning_rate": 4.360127974405119e-05,
      "loss": 1.5649,
      "step": 1920
    },
    {
      "epoch": 0.3859228154369126,
      "grad_norm": 12.016615867614746,
      "learning_rate": 4.356795307605146e-05,
      "loss": 1.3232,
      "step": 1930
    },
    {
      "epoch": 0.3879224155168966,
      "grad_norm": 11.33920669555664,
      "learning_rate": 4.3534626408051725e-05,
      "loss": 1.4063,
      "step": 1940
    },
    {
      "epoch": 0.3899220155968806,
      "grad_norm": 8.669095039367676,
      "learning_rate": 4.3501299740051995e-05,
      "loss": 1.4773,
      "step": 1950
    },
    {
      "epoch": 0.3919216156768646,
      "grad_norm": 10.304688453674316,
      "learning_rate": 4.346797307205226e-05,
      "loss": 1.196,
      "step": 1960
    },
    {
      "epoch": 0.39392121575684863,
      "grad_norm": 8.115824699401855,
      "learning_rate": 4.343464640405253e-05,
      "loss": 1.1125,
      "step": 1970
    },
    {
      "epoch": 0.39592081583683264,
      "grad_norm": 7.063497066497803,
      "learning_rate": 4.340131973605279e-05,
      "loss": 1.3435,
      "step": 1980
    },
    {
      "epoch": 0.39792041591681665,
      "grad_norm": 8.129348754882812,
      "learning_rate": 4.3367993068053056e-05,
      "loss": 1.1309,
      "step": 1990
    },
    {
      "epoch": 0.39992001599680066,
      "grad_norm": 8.476826667785645,
      "learning_rate": 4.3334666400053326e-05,
      "loss": 1.4277,
      "step": 2000
    },
    {
      "epoch": 0.40191961607678467,
      "grad_norm": 14.241874694824219,
      "learning_rate": 4.330133973205359e-05,
      "loss": 1.2404,
      "step": 2010
    },
    {
      "epoch": 0.4039192161567686,
      "grad_norm": 7.7841315269470215,
      "learning_rate": 4.326801306405386e-05,
      "loss": 1.0315,
      "step": 2020
    },
    {
      "epoch": 0.40591881623675263,
      "grad_norm": 9.687084197998047,
      "learning_rate": 4.3234686396054124e-05,
      "loss": 1.3285,
      "step": 2030
    },
    {
      "epoch": 0.40791841631673664,
      "grad_norm": 11.329412460327148,
      "learning_rate": 4.3201359728054394e-05,
      "loss": 1.3635,
      "step": 2040
    },
    {
      "epoch": 0.40991801639672065,
      "grad_norm": 9.064562797546387,
      "learning_rate": 4.316803306005466e-05,
      "loss": 1.541,
      "step": 2050
    },
    {
      "epoch": 0.41191761647670466,
      "grad_norm": 7.466919422149658,
      "learning_rate": 4.313470639205493e-05,
      "loss": 1.2689,
      "step": 2060
    },
    {
      "epoch": 0.41391721655668867,
      "grad_norm": 8.256321907043457,
      "learning_rate": 4.310137972405519e-05,
      "loss": 1.6079,
      "step": 2070
    },
    {
      "epoch": 0.4159168166366727,
      "grad_norm": 8.191024780273438,
      "learning_rate": 4.3068053056055455e-05,
      "loss": 1.2105,
      "step": 2080
    },
    {
      "epoch": 0.4179164167166567,
      "grad_norm": 16.89287567138672,
      "learning_rate": 4.3034726388055725e-05,
      "loss": 1.3279,
      "step": 2090
    },
    {
      "epoch": 0.41991601679664065,
      "grad_norm": 6.810368537902832,
      "learning_rate": 4.300139972005599e-05,
      "loss": 1.3173,
      "step": 2100
    },
    {
      "epoch": 0.42191561687662466,
      "grad_norm": 6.354698657989502,
      "learning_rate": 4.296807305205626e-05,
      "loss": 1.3385,
      "step": 2110
    },
    {
      "epoch": 0.42391521695660866,
      "grad_norm": 12.645870208740234,
      "learning_rate": 4.293474638405652e-05,
      "loss": 1.4435,
      "step": 2120
    },
    {
      "epoch": 0.4259148170365927,
      "grad_norm": 9.203939437866211,
      "learning_rate": 4.290141971605679e-05,
      "loss": 1.4086,
      "step": 2130
    },
    {
      "epoch": 0.4279144171165767,
      "grad_norm": 12.003053665161133,
      "learning_rate": 4.2868093048057056e-05,
      "loss": 1.3651,
      "step": 2140
    },
    {
      "epoch": 0.4299140171965607,
      "grad_norm": 7.764573574066162,
      "learning_rate": 4.2834766380057326e-05,
      "loss": 1.4471,
      "step": 2150
    },
    {
      "epoch": 0.4319136172765447,
      "grad_norm": 9.585809707641602,
      "learning_rate": 4.280143971205759e-05,
      "loss": 1.3044,
      "step": 2160
    },
    {
      "epoch": 0.4339132173565287,
      "grad_norm": 19.769412994384766,
      "learning_rate": 4.276811304405785e-05,
      "loss": 1.2034,
      "step": 2170
    },
    {
      "epoch": 0.4359128174365127,
      "grad_norm": 10.261392593383789,
      "learning_rate": 4.2734786376058123e-05,
      "loss": 1.3423,
      "step": 2180
    },
    {
      "epoch": 0.4379124175164967,
      "grad_norm": 6.7034478187561035,
      "learning_rate": 4.270145970805839e-05,
      "loss": 1.1584,
      "step": 2190
    },
    {
      "epoch": 0.4399120175964807,
      "grad_norm": 13.299567222595215,
      "learning_rate": 4.266813304005866e-05,
      "loss": 1.5279,
      "step": 2200
    },
    {
      "epoch": 0.4419116176764647,
      "grad_norm": 8.817646980285645,
      "learning_rate": 4.263480637205892e-05,
      "loss": 1.4097,
      "step": 2210
    },
    {
      "epoch": 0.4439112177564487,
      "grad_norm": 10.895479202270508,
      "learning_rate": 4.260147970405919e-05,
      "loss": 1.1805,
      "step": 2220
    },
    {
      "epoch": 0.4459108178364327,
      "grad_norm": 7.209839344024658,
      "learning_rate": 4.2568153036059455e-05,
      "loss": 1.0239,
      "step": 2230
    },
    {
      "epoch": 0.4479104179164167,
      "grad_norm": 10.350363731384277,
      "learning_rate": 4.2534826368059725e-05,
      "loss": 1.4044,
      "step": 2240
    },
    {
      "epoch": 0.44991001799640074,
      "grad_norm": 9.756516456604004,
      "learning_rate": 4.250149970005999e-05,
      "loss": 1.1526,
      "step": 2250
    },
    {
      "epoch": 0.45190961807638474,
      "grad_norm": 11.944194793701172,
      "learning_rate": 4.246817303206025e-05,
      "loss": 1.6343,
      "step": 2260
    },
    {
      "epoch": 0.4539092181563687,
      "grad_norm": 11.264093399047852,
      "learning_rate": 4.243484636406052e-05,
      "loss": 1.2512,
      "step": 2270
    },
    {
      "epoch": 0.4559088182363527,
      "grad_norm": 9.32564926147461,
      "learning_rate": 4.2401519696060786e-05,
      "loss": 1.2642,
      "step": 2280
    },
    {
      "epoch": 0.4579084183163367,
      "grad_norm": 10.246231079101562,
      "learning_rate": 4.2368193028061056e-05,
      "loss": 1.2339,
      "step": 2290
    },
    {
      "epoch": 0.45990801839632073,
      "grad_norm": 7.710769176483154,
      "learning_rate": 4.233486636006132e-05,
      "loss": 1.1466,
      "step": 2300
    },
    {
      "epoch": 0.46190761847630474,
      "grad_norm": 10.273658752441406,
      "learning_rate": 4.230153969206159e-05,
      "loss": 1.3991,
      "step": 2310
    },
    {
      "epoch": 0.46390721855628875,
      "grad_norm": 9.619648933410645,
      "learning_rate": 4.226821302406186e-05,
      "loss": 1.2619,
      "step": 2320
    },
    {
      "epoch": 0.46590681863627276,
      "grad_norm": 5.6224493980407715,
      "learning_rate": 4.2234886356062123e-05,
      "loss": 1.1529,
      "step": 2330
    },
    {
      "epoch": 0.46790641871625677,
      "grad_norm": 6.693117618560791,
      "learning_rate": 4.2201559688062394e-05,
      "loss": 1.0262,
      "step": 2340
    },
    {
      "epoch": 0.4699060187962408,
      "grad_norm": 12.3672513961792,
      "learning_rate": 4.216823302006266e-05,
      "loss": 1.2952,
      "step": 2350
    },
    {
      "epoch": 0.47190561887622473,
      "grad_norm": 14.722169876098633,
      "learning_rate": 4.213490635206293e-05,
      "loss": 1.1985,
      "step": 2360
    },
    {
      "epoch": 0.47390521895620874,
      "grad_norm": 8.191874504089355,
      "learning_rate": 4.210157968406319e-05,
      "loss": 1.5322,
      "step": 2370
    },
    {
      "epoch": 0.47590481903619275,
      "grad_norm": 6.439329624176025,
      "learning_rate": 4.206825301606346e-05,
      "loss": 1.3296,
      "step": 2380
    },
    {
      "epoch": 0.47790441911617676,
      "grad_norm": 5.884023189544678,
      "learning_rate": 4.2034926348063725e-05,
      "loss": 1.2206,
      "step": 2390
    },
    {
      "epoch": 0.47990401919616077,
      "grad_norm": 11.148348808288574,
      "learning_rate": 4.200159968006399e-05,
      "loss": 1.4249,
      "step": 2400
    },
    {
      "epoch": 0.4819036192761448,
      "grad_norm": 10.005032539367676,
      "learning_rate": 4.196827301206426e-05,
      "loss": 1.0862,
      "step": 2410
    },
    {
      "epoch": 0.4839032193561288,
      "grad_norm": 6.979532241821289,
      "learning_rate": 4.193494634406452e-05,
      "loss": 1.2102,
      "step": 2420
    },
    {
      "epoch": 0.4859028194361128,
      "grad_norm": 10.417128562927246,
      "learning_rate": 4.190161967606479e-05,
      "loss": 1.3869,
      "step": 2430
    },
    {
      "epoch": 0.4879024195160968,
      "grad_norm": 9.855016708374023,
      "learning_rate": 4.1868293008065056e-05,
      "loss": 1.4188,
      "step": 2440
    },
    {
      "epoch": 0.48990201959608076,
      "grad_norm": 8.409106254577637,
      "learning_rate": 4.1834966340065326e-05,
      "loss": 1.3839,
      "step": 2450
    },
    {
      "epoch": 0.49190161967606477,
      "grad_norm": 9.7792329788208,
      "learning_rate": 4.180163967206559e-05,
      "loss": 1.3037,
      "step": 2460
    },
    {
      "epoch": 0.4939012197560488,
      "grad_norm": 10.044366836547852,
      "learning_rate": 4.176831300406586e-05,
      "loss": 1.2748,
      "step": 2470
    },
    {
      "epoch": 0.4959008198360328,
      "grad_norm": 9.707967758178711,
      "learning_rate": 4.1734986336066123e-05,
      "loss": 1.2917,
      "step": 2480
    },
    {
      "epoch": 0.4979004199160168,
      "grad_norm": 10.713278770446777,
      "learning_rate": 4.170165966806639e-05,
      "loss": 1.2926,
      "step": 2490
    },
    {
      "epoch": 0.4999000199960008,
      "grad_norm": 8.194883346557617,
      "learning_rate": 4.166833300006666e-05,
      "loss": 1.3953,
      "step": 2500
    },
    {
      "epoch": 0.5018996200759848,
      "grad_norm": 12.108803749084473,
      "learning_rate": 4.163500633206692e-05,
      "loss": 1.2468,
      "step": 2510
    },
    {
      "epoch": 0.5038992201559688,
      "grad_norm": 8.096705436706543,
      "learning_rate": 4.160167966406719e-05,
      "loss": 1.5883,
      "step": 2520
    },
    {
      "epoch": 0.5058988202359528,
      "grad_norm": 6.243859767913818,
      "learning_rate": 4.1568352996067454e-05,
      "loss": 1.5474,
      "step": 2530
    },
    {
      "epoch": 0.5078984203159368,
      "grad_norm": 7.659424304962158,
      "learning_rate": 4.1535026328067725e-05,
      "loss": 1.5919,
      "step": 2540
    },
    {
      "epoch": 0.5098980203959208,
      "grad_norm": 8.2278470993042,
      "learning_rate": 4.150169966006799e-05,
      "loss": 1.1875,
      "step": 2550
    },
    {
      "epoch": 0.5118976204759048,
      "grad_norm": 10.82964038848877,
      "learning_rate": 4.146837299206825e-05,
      "loss": 1.5497,
      "step": 2560
    },
    {
      "epoch": 0.5138972205558888,
      "grad_norm": 8.458332061767578,
      "learning_rate": 4.143504632406852e-05,
      "loss": 1.2138,
      "step": 2570
    },
    {
      "epoch": 0.5158968206358728,
      "grad_norm": 10.303706169128418,
      "learning_rate": 4.1401719656068786e-05,
      "loss": 1.167,
      "step": 2580
    },
    {
      "epoch": 0.5178964207158568,
      "grad_norm": 8.409741401672363,
      "learning_rate": 4.1368392988069056e-05,
      "loss": 1.3977,
      "step": 2590
    },
    {
      "epoch": 0.5198960207958409,
      "grad_norm": 9.65929126739502,
      "learning_rate": 4.133506632006932e-05,
      "loss": 1.4502,
      "step": 2600
    },
    {
      "epoch": 0.5218956208758249,
      "grad_norm": 9.120354652404785,
      "learning_rate": 4.130173965206959e-05,
      "loss": 1.2112,
      "step": 2610
    },
    {
      "epoch": 0.5238952209558089,
      "grad_norm": 11.970780372619629,
      "learning_rate": 4.126841298406985e-05,
      "loss": 1.2607,
      "step": 2620
    },
    {
      "epoch": 0.5258948210357929,
      "grad_norm": 11.290714263916016,
      "learning_rate": 4.123508631607012e-05,
      "loss": 1.3214,
      "step": 2630
    },
    {
      "epoch": 0.5278944211157769,
      "grad_norm": 8.56667709350586,
      "learning_rate": 4.120175964807039e-05,
      "loss": 1.2839,
      "step": 2640
    },
    {
      "epoch": 0.5298940211957609,
      "grad_norm": 14.916085243225098,
      "learning_rate": 4.116843298007065e-05,
      "loss": 1.644,
      "step": 2650
    },
    {
      "epoch": 0.5318936212757448,
      "grad_norm": 19.220802307128906,
      "learning_rate": 4.113510631207092e-05,
      "loss": 1.3359,
      "step": 2660
    },
    {
      "epoch": 0.5338932213557288,
      "grad_norm": 10.924009323120117,
      "learning_rate": 4.1101779644071184e-05,
      "loss": 1.222,
      "step": 2670
    },
    {
      "epoch": 0.5358928214357128,
      "grad_norm": 7.355231761932373,
      "learning_rate": 4.1068452976071454e-05,
      "loss": 1.3494,
      "step": 2680
    },
    {
      "epoch": 0.5378924215156968,
      "grad_norm": 11.765384674072266,
      "learning_rate": 4.103512630807172e-05,
      "loss": 1.2495,
      "step": 2690
    },
    {
      "epoch": 0.5398920215956808,
      "grad_norm": 17.74324607849121,
      "learning_rate": 4.100179964007199e-05,
      "loss": 1.3723,
      "step": 2700
    },
    {
      "epoch": 0.5418916216756648,
      "grad_norm": 8.6763334274292,
      "learning_rate": 4.096847297207225e-05,
      "loss": 1.2759,
      "step": 2710
    },
    {
      "epoch": 0.5438912217556489,
      "grad_norm": 11.438884735107422,
      "learning_rate": 4.093514630407252e-05,
      "loss": 1.2887,
      "step": 2720
    },
    {
      "epoch": 0.5458908218356329,
      "grad_norm": 13.431958198547363,
      "learning_rate": 4.0901819636072785e-05,
      "loss": 1.1635,
      "step": 2730
    },
    {
      "epoch": 0.5478904219156169,
      "grad_norm": 13.024909973144531,
      "learning_rate": 4.086849296807305e-05,
      "loss": 1.3041,
      "step": 2740
    },
    {
      "epoch": 0.5498900219956009,
      "grad_norm": 12.283001899719238,
      "learning_rate": 4.083516630007332e-05,
      "loss": 1.3644,
      "step": 2750
    },
    {
      "epoch": 0.5518896220755849,
      "grad_norm": 7.722893238067627,
      "learning_rate": 4.080183963207358e-05,
      "loss": 1.2789,
      "step": 2760
    },
    {
      "epoch": 0.5538892221555689,
      "grad_norm": 9.883880615234375,
      "learning_rate": 4.076851296407385e-05,
      "loss": 1.1748,
      "step": 2770
    },
    {
      "epoch": 0.5558888222355529,
      "grad_norm": 6.70943021774292,
      "learning_rate": 4.0735186296074117e-05,
      "loss": 1.5044,
      "step": 2780
    },
    {
      "epoch": 0.5578884223155369,
      "grad_norm": 12.161844253540039,
      "learning_rate": 4.070185962807439e-05,
      "loss": 1.2099,
      "step": 2790
    },
    {
      "epoch": 0.5598880223955209,
      "grad_norm": 10.237136840820312,
      "learning_rate": 4.066853296007465e-05,
      "loss": 1.2317,
      "step": 2800
    },
    {
      "epoch": 0.5618876224755049,
      "grad_norm": 15.287521362304688,
      "learning_rate": 4.063520629207492e-05,
      "loss": 1.2061,
      "step": 2810
    },
    {
      "epoch": 0.563887222555489,
      "grad_norm": 14.262770652770996,
      "learning_rate": 4.0601879624075184e-05,
      "loss": 1.1119,
      "step": 2820
    },
    {
      "epoch": 0.5658868226354729,
      "grad_norm": 6.919824600219727,
      "learning_rate": 4.0568552956075454e-05,
      "loss": 1.3667,
      "step": 2830
    },
    {
      "epoch": 0.5678864227154569,
      "grad_norm": 14.183902740478516,
      "learning_rate": 4.0535226288075725e-05,
      "loss": 1.3654,
      "step": 2840
    },
    {
      "epoch": 0.5698860227954409,
      "grad_norm": 9.950738906860352,
      "learning_rate": 4.050189962007599e-05,
      "loss": 1.5347,
      "step": 2850
    },
    {
      "epoch": 0.5718856228754249,
      "grad_norm": 13.368810653686523,
      "learning_rate": 4.046857295207626e-05,
      "loss": 1.049,
      "step": 2860
    },
    {
      "epoch": 0.5738852229554089,
      "grad_norm": 8.22337532043457,
      "learning_rate": 4.043524628407652e-05,
      "loss": 1.3517,
      "step": 2870
    },
    {
      "epoch": 0.5758848230353929,
      "grad_norm": 7.839128017425537,
      "learning_rate": 4.0401919616076785e-05,
      "loss": 1.1669,
      "step": 2880
    },
    {
      "epoch": 0.5778844231153769,
      "grad_norm": 7.4061970710754395,
      "learning_rate": 4.0368592948077056e-05,
      "loss": 1.0605,
      "step": 2890
    },
    {
      "epoch": 0.5798840231953609,
      "grad_norm": 9.438356399536133,
      "learning_rate": 4.033526628007732e-05,
      "loss": 1.6649,
      "step": 2900
    },
    {
      "epoch": 0.5818836232753449,
      "grad_norm": 11.02318286895752,
      "learning_rate": 4.030193961207759e-05,
      "loss": 1.1835,
      "step": 2910
    },
    {
      "epoch": 0.5838832233553289,
      "grad_norm": 9.416038513183594,
      "learning_rate": 4.026861294407785e-05,
      "loss": 1.3389,
      "step": 2920
    },
    {
      "epoch": 0.585882823435313,
      "grad_norm": 8.444393157958984,
      "learning_rate": 4.023528627607812e-05,
      "loss": 1.3769,
      "step": 2930
    },
    {
      "epoch": 0.587882423515297,
      "grad_norm": 6.090178966522217,
      "learning_rate": 4.020195960807839e-05,
      "loss": 1.2626,
      "step": 2940
    },
    {
      "epoch": 0.589882023595281,
      "grad_norm": 14.910218238830566,
      "learning_rate": 4.016863294007866e-05,
      "loss": 1.176,
      "step": 2950
    },
    {
      "epoch": 0.591881623675265,
      "grad_norm": 16.014402389526367,
      "learning_rate": 4.013530627207892e-05,
      "loss": 1.1762,
      "step": 2960
    },
    {
      "epoch": 0.593881223755249,
      "grad_norm": 6.923309326171875,
      "learning_rate": 4.0101979604079184e-05,
      "loss": 1.0968,
      "step": 2970
    },
    {
      "epoch": 0.595880823835233,
      "grad_norm": 17.23565101623535,
      "learning_rate": 4.0068652936079454e-05,
      "loss": 1.199,
      "step": 2980
    },
    {
      "epoch": 0.597880423915217,
      "grad_norm": 12.468880653381348,
      "learning_rate": 4.003532626807972e-05,
      "loss": 1.3443,
      "step": 2990
    },
    {
      "epoch": 0.5998800239952009,
      "grad_norm": 10.071290969848633,
      "learning_rate": 4.000199960007999e-05,
      "loss": 1.1263,
      "step": 3000
    },
    {
      "epoch": 0.6018796240751849,
      "grad_norm": 10.354352951049805,
      "learning_rate": 3.996867293208025e-05,
      "loss": 1.3717,
      "step": 3010
    },
    {
      "epoch": 0.6038792241551689,
      "grad_norm": 11.601980209350586,
      "learning_rate": 3.993534626408052e-05,
      "loss": 1.1071,
      "step": 3020
    },
    {
      "epoch": 0.6058788242351529,
      "grad_norm": 18.797748565673828,
      "learning_rate": 3.9902019596080785e-05,
      "loss": 1.3429,
      "step": 3030
    },
    {
      "epoch": 0.607878424315137,
      "grad_norm": 9.523914337158203,
      "learning_rate": 3.9868692928081056e-05,
      "loss": 1.3549,
      "step": 3040
    },
    {
      "epoch": 0.609878024395121,
      "grad_norm": 20.726600646972656,
      "learning_rate": 3.983536626008132e-05,
      "loss": 1.219,
      "step": 3050
    },
    {
      "epoch": 0.611877624475105,
      "grad_norm": 13.368647575378418,
      "learning_rate": 3.980203959208158e-05,
      "loss": 1.3893,
      "step": 3060
    },
    {
      "epoch": 0.613877224555089,
      "grad_norm": 10.923848152160645,
      "learning_rate": 3.976871292408185e-05,
      "loss": 1.2772,
      "step": 3070
    },
    {
      "epoch": 0.615876824635073,
      "grad_norm": 7.875560760498047,
      "learning_rate": 3.9735386256082116e-05,
      "loss": 1.1633,
      "step": 3080
    },
    {
      "epoch": 0.617876424715057,
      "grad_norm": 11.409017562866211,
      "learning_rate": 3.970205958808239e-05,
      "loss": 1.0883,
      "step": 3090
    },
    {
      "epoch": 0.619876024795041,
      "grad_norm": 7.789727687835693,
      "learning_rate": 3.966873292008265e-05,
      "loss": 1.3719,
      "step": 3100
    },
    {
      "epoch": 0.621875624875025,
      "grad_norm": 8.09294319152832,
      "learning_rate": 3.963540625208292e-05,
      "loss": 1.1676,
      "step": 3110
    },
    {
      "epoch": 0.623875224955009,
      "grad_norm": 9.983613014221191,
      "learning_rate": 3.9602079584083184e-05,
      "loss": 1.2901,
      "step": 3120
    },
    {
      "epoch": 0.625874825034993,
      "grad_norm": 16.45145034790039,
      "learning_rate": 3.9568752916083454e-05,
      "loss": 1.4913,
      "step": 3130
    },
    {
      "epoch": 0.627874425114977,
      "grad_norm": 13.140570640563965,
      "learning_rate": 3.953542624808372e-05,
      "loss": 1.3606,
      "step": 3140
    },
    {
      "epoch": 0.629874025194961,
      "grad_norm": 9.14824104309082,
      "learning_rate": 3.950209958008398e-05,
      "loss": 0.9801,
      "step": 3150
    },
    {
      "epoch": 0.6318736252749451,
      "grad_norm": 10.571456909179688,
      "learning_rate": 3.946877291208425e-05,
      "loss": 1.3986,
      "step": 3160
    },
    {
      "epoch": 0.633873225354929,
      "grad_norm": 9.13987922668457,
      "learning_rate": 3.9435446244084515e-05,
      "loss": 1.2015,
      "step": 3170
    },
    {
      "epoch": 0.635872825434913,
      "grad_norm": 19.51978874206543,
      "learning_rate": 3.9402119576084785e-05,
      "loss": 1.3393,
      "step": 3180
    },
    {
      "epoch": 0.637872425514897,
      "grad_norm": 7.830604553222656,
      "learning_rate": 3.936879290808505e-05,
      "loss": 1.4424,
      "step": 3190
    },
    {
      "epoch": 0.639872025594881,
      "grad_norm": 13.370462417602539,
      "learning_rate": 3.933546624008532e-05,
      "loss": 1.2709,
      "step": 3200
    },
    {
      "epoch": 0.641871625674865,
      "grad_norm": 10.603973388671875,
      "learning_rate": 3.930213957208558e-05,
      "loss": 1.4042,
      "step": 3210
    },
    {
      "epoch": 0.643871225754849,
      "grad_norm": 10.764043807983398,
      "learning_rate": 3.926881290408585e-05,
      "loss": 1.1157,
      "step": 3220
    },
    {
      "epoch": 0.645870825834833,
      "grad_norm": 13.663467407226562,
      "learning_rate": 3.9235486236086116e-05,
      "loss": 1.1413,
      "step": 3230
    },
    {
      "epoch": 0.647870425914817,
      "grad_norm": 9.756425857543945,
      "learning_rate": 3.920215956808638e-05,
      "loss": 1.2439,
      "step": 3240
    },
    {
      "epoch": 0.649870025994801,
      "grad_norm": 7.393795490264893,
      "learning_rate": 3.916883290008665e-05,
      "loss": 0.9973,
      "step": 3250
    },
    {
      "epoch": 0.651869626074785,
      "grad_norm": 11.991584777832031,
      "learning_rate": 3.9135506232086914e-05,
      "loss": 1.1343,
      "step": 3260
    },
    {
      "epoch": 0.6538692261547691,
      "grad_norm": 7.072484493255615,
      "learning_rate": 3.9102179564087184e-05,
      "loss": 1.1824,
      "step": 3270
    },
    {
      "epoch": 0.6558688262347531,
      "grad_norm": 14.368646621704102,
      "learning_rate": 3.906885289608745e-05,
      "loss": 1.3315,
      "step": 3280
    },
    {
      "epoch": 0.6578684263147371,
      "grad_norm": 12.82465934753418,
      "learning_rate": 3.903552622808772e-05,
      "loss": 1.2157,
      "step": 3290
    },
    {
      "epoch": 0.6598680263947211,
      "grad_norm": 13.874706268310547,
      "learning_rate": 3.900219956008798e-05,
      "loss": 1.1154,
      "step": 3300
    },
    {
      "epoch": 0.6618676264747051,
      "grad_norm": 11.70471477508545,
      "learning_rate": 3.896887289208825e-05,
      "loss": 1.4185,
      "step": 3310
    },
    {
      "epoch": 0.6638672265546891,
      "grad_norm": 14.185334205627441,
      "learning_rate": 3.8935546224088515e-05,
      "loss": 1.3941,
      "step": 3320
    },
    {
      "epoch": 0.6658668266346731,
      "grad_norm": 11.32946491241455,
      "learning_rate": 3.890221955608878e-05,
      "loss": 1.4729,
      "step": 3330
    },
    {
      "epoch": 0.667866426714657,
      "grad_norm": 8.55795669555664,
      "learning_rate": 3.8868892888089056e-05,
      "loss": 1.2327,
      "step": 3340
    },
    {
      "epoch": 0.669866026794641,
      "grad_norm": 18.567283630371094,
      "learning_rate": 3.883556622008932e-05,
      "loss": 1.3003,
      "step": 3350
    },
    {
      "epoch": 0.671865626874625,
      "grad_norm": 14.00277328491211,
      "learning_rate": 3.880223955208959e-05,
      "loss": 1.3131,
      "step": 3360
    },
    {
      "epoch": 0.673865226954609,
      "grad_norm": 9.731492042541504,
      "learning_rate": 3.876891288408985e-05,
      "loss": 1.3762,
      "step": 3370
    },
    {
      "epoch": 0.675864827034593,
      "grad_norm": 11.062589645385742,
      "learning_rate": 3.8735586216090116e-05,
      "loss": 1.1645,
      "step": 3380
    },
    {
      "epoch": 0.6778644271145771,
      "grad_norm": 12.758499145507812,
      "learning_rate": 3.870225954809039e-05,
      "loss": 1.2923,
      "step": 3390
    },
    {
      "epoch": 0.6798640271945611,
      "grad_norm": 11.518110275268555,
      "learning_rate": 3.866893288009065e-05,
      "loss": 1.2215,
      "step": 3400
    },
    {
      "epoch": 0.6818636272745451,
      "grad_norm": 8.667983055114746,
      "learning_rate": 3.863560621209092e-05,
      "loss": 1.1419,
      "step": 3410
    },
    {
      "epoch": 0.6838632273545291,
      "grad_norm": 10.714900970458984,
      "learning_rate": 3.8602279544091184e-05,
      "loss": 1.4783,
      "step": 3420
    },
    {
      "epoch": 0.6858628274345131,
      "grad_norm": 5.994640827178955,
      "learning_rate": 3.8568952876091454e-05,
      "loss": 1.2491,
      "step": 3430
    },
    {
      "epoch": 0.6878624275144971,
      "grad_norm": 7.661020755767822,
      "learning_rate": 3.853562620809172e-05,
      "loss": 1.2888,
      "step": 3440
    },
    {
      "epoch": 0.6898620275944811,
      "grad_norm": 8.590173721313477,
      "learning_rate": 3.850229954009199e-05,
      "loss": 1.2561,
      "step": 3450
    },
    {
      "epoch": 0.6918616276744651,
      "grad_norm": 6.554612636566162,
      "learning_rate": 3.846897287209225e-05,
      "loss": 1.3874,
      "step": 3460
    },
    {
      "epoch": 0.6938612277544491,
      "grad_norm": 7.30633544921875,
      "learning_rate": 3.8435646204092515e-05,
      "loss": 1.0389,
      "step": 3470
    },
    {
      "epoch": 0.6958608278344331,
      "grad_norm": 9.767383575439453,
      "learning_rate": 3.8402319536092785e-05,
      "loss": 1.1564,
      "step": 3480
    },
    {
      "epoch": 0.6978604279144172,
      "grad_norm": 17.199951171875,
      "learning_rate": 3.836899286809305e-05,
      "loss": 1.3786,
      "step": 3490
    },
    {
      "epoch": 0.6998600279944012,
      "grad_norm": 12.99984073638916,
      "learning_rate": 3.833566620009332e-05,
      "loss": 1.0717,
      "step": 3500
    },
    {
      "epoch": 0.7018596280743852,
      "grad_norm": 10.522557258605957,
      "learning_rate": 3.830233953209358e-05,
      "loss": 1.3302,
      "step": 3510
    },
    {
      "epoch": 0.7038592281543691,
      "grad_norm": 6.328661918640137,
      "learning_rate": 3.826901286409385e-05,
      "loss": 1.0549,
      "step": 3520
    },
    {
      "epoch": 0.7058588282343531,
      "grad_norm": 6.699892997741699,
      "learning_rate": 3.8235686196094116e-05,
      "loss": 1.0214,
      "step": 3530
    },
    {
      "epoch": 0.7078584283143371,
      "grad_norm": 9.971946716308594,
      "learning_rate": 3.820235952809439e-05,
      "loss": 1.4373,
      "step": 3540
    },
    {
      "epoch": 0.7098580283943211,
      "grad_norm": 9.8873291015625,
      "learning_rate": 3.816903286009465e-05,
      "loss": 1.0573,
      "step": 3550
    },
    {
      "epoch": 0.7118576284743051,
      "grad_norm": 11.81954288482666,
      "learning_rate": 3.8135706192094914e-05,
      "loss": 1.1712,
      "step": 3560
    },
    {
      "epoch": 0.7138572285542891,
      "grad_norm": 8.340261459350586,
      "learning_rate": 3.8102379524095184e-05,
      "loss": 1.324,
      "step": 3570
    },
    {
      "epoch": 0.7158568286342731,
      "grad_norm": 9.43123722076416,
      "learning_rate": 3.806905285609545e-05,
      "loss": 1.1287,
      "step": 3580
    },
    {
      "epoch": 0.7178564287142571,
      "grad_norm": 14.495919227600098,
      "learning_rate": 3.803572618809572e-05,
      "loss": 1.4844,
      "step": 3590
    },
    {
      "epoch": 0.7198560287942412,
      "grad_norm": 8.78662395477295,
      "learning_rate": 3.800239952009598e-05,
      "loss": 1.3817,
      "step": 3600
    },
    {
      "epoch": 0.7218556288742252,
      "grad_norm": 9.767730712890625,
      "learning_rate": 3.796907285209625e-05,
      "loss": 0.9198,
      "step": 3610
    },
    {
      "epoch": 0.7238552289542092,
      "grad_norm": 12.570734024047852,
      "learning_rate": 3.7935746184096515e-05,
      "loss": 1.1038,
      "step": 3620
    },
    {
      "epoch": 0.7258548290341932,
      "grad_norm": 21.11334228515625,
      "learning_rate": 3.7902419516096785e-05,
      "loss": 1.1425,
      "step": 3630
    },
    {
      "epoch": 0.7278544291141772,
      "grad_norm": 7.805469512939453,
      "learning_rate": 3.786909284809705e-05,
      "loss": 1.0135,
      "step": 3640
    },
    {
      "epoch": 0.7298540291941612,
      "grad_norm": 8.64013671875,
      "learning_rate": 3.783576618009731e-05,
      "loss": 1.1986,
      "step": 3650
    },
    {
      "epoch": 0.7318536292741452,
      "grad_norm": 14.696758270263672,
      "learning_rate": 3.780243951209758e-05,
      "loss": 1.3546,
      "step": 3660
    },
    {
      "epoch": 0.7338532293541292,
      "grad_norm": 11.276936531066895,
      "learning_rate": 3.7769112844097846e-05,
      "loss": 1.3429,
      "step": 3670
    },
    {
      "epoch": 0.7358528294341132,
      "grad_norm": 17.966609954833984,
      "learning_rate": 3.7735786176098116e-05,
      "loss": 1.0624,
      "step": 3680
    },
    {
      "epoch": 0.7378524295140971,
      "grad_norm": 13.770709037780762,
      "learning_rate": 3.770245950809838e-05,
      "loss": 1.2056,
      "step": 3690
    },
    {
      "epoch": 0.7398520295940811,
      "grad_norm": 6.752033710479736,
      "learning_rate": 3.766913284009865e-05,
      "loss": 1.1658,
      "step": 3700
    },
    {
      "epoch": 0.7418516296740651,
      "grad_norm": 11.799617767333984,
      "learning_rate": 3.7635806172098914e-05,
      "loss": 1.1856,
      "step": 3710
    },
    {
      "epoch": 0.7438512297540492,
      "grad_norm": 17.172138214111328,
      "learning_rate": 3.7602479504099184e-05,
      "loss": 1.2781,
      "step": 3720
    },
    {
      "epoch": 0.7458508298340332,
      "grad_norm": 15.196943283081055,
      "learning_rate": 3.756915283609945e-05,
      "loss": 1.2169,
      "step": 3730
    },
    {
      "epoch": 0.7478504299140172,
      "grad_norm": 4.767385482788086,
      "learning_rate": 3.753582616809971e-05,
      "loss": 1.2243,
      "step": 3740
    },
    {
      "epoch": 0.7498500299940012,
      "grad_norm": 13.462945938110352,
      "learning_rate": 3.750249950009998e-05,
      "loss": 1.4067,
      "step": 3750
    },
    {
      "epoch": 0.7518496300739852,
      "grad_norm": 7.2137370109558105,
      "learning_rate": 3.7469172832100245e-05,
      "loss": 1.2452,
      "step": 3760
    },
    {
      "epoch": 0.7538492301539692,
      "grad_norm": 6.6230058670043945,
      "learning_rate": 3.7435846164100515e-05,
      "loss": 1.0704,
      "step": 3770
    },
    {
      "epoch": 0.7558488302339532,
      "grad_norm": 11.077132225036621,
      "learning_rate": 3.740251949610078e-05,
      "loss": 1.4128,
      "step": 3780
    },
    {
      "epoch": 0.7578484303139372,
      "grad_norm": 15.635919570922852,
      "learning_rate": 3.736919282810105e-05,
      "loss": 1.2471,
      "step": 3790
    },
    {
      "epoch": 0.7598480303939212,
      "grad_norm": 25.102005004882812,
      "learning_rate": 3.733586616010131e-05,
      "loss": 1.2006,
      "step": 3800
    },
    {
      "epoch": 0.7618476304739052,
      "grad_norm": 4.534594535827637,
      "learning_rate": 3.730253949210158e-05,
      "loss": 1.2177,
      "step": 3810
    },
    {
      "epoch": 0.7638472305538893,
      "grad_norm": 8.330376625061035,
      "learning_rate": 3.7269212824101846e-05,
      "loss": 1.2563,
      "step": 3820
    },
    {
      "epoch": 0.7658468306338733,
      "grad_norm": 5.789188861846924,
      "learning_rate": 3.723588615610211e-05,
      "loss": 1.1185,
      "step": 3830
    },
    {
      "epoch": 0.7678464307138573,
      "grad_norm": 11.026089668273926,
      "learning_rate": 3.720255948810238e-05,
      "loss": 1.0352,
      "step": 3840
    },
    {
      "epoch": 0.7698460307938413,
      "grad_norm": 7.858421802520752,
      "learning_rate": 3.716923282010264e-05,
      "loss": 1.1111,
      "step": 3850
    },
    {
      "epoch": 0.7718456308738252,
      "grad_norm": 12.779881477355957,
      "learning_rate": 3.713590615210292e-05,
      "loss": 1.113,
      "step": 3860
    },
    {
      "epoch": 0.7738452309538092,
      "grad_norm": 2.9998302459716797,
      "learning_rate": 3.7102579484103184e-05,
      "loss": 1.2392,
      "step": 3870
    },
    {
      "epoch": 0.7758448310337932,
      "grad_norm": 9.57577133178711,
      "learning_rate": 3.706925281610345e-05,
      "loss": 1.1163,
      "step": 3880
    },
    {
      "epoch": 0.7778444311137772,
      "grad_norm": 9.906031608581543,
      "learning_rate": 3.703592614810372e-05,
      "loss": 1.2483,
      "step": 3890
    },
    {
      "epoch": 0.7798440311937612,
      "grad_norm": 18.57105827331543,
      "learning_rate": 3.700259948010398e-05,
      "loss": 1.2075,
      "step": 3900
    },
    {
      "epoch": 0.7818436312737452,
      "grad_norm": 26.144001007080078,
      "learning_rate": 3.696927281210425e-05,
      "loss": 1.3552,
      "step": 3910
    },
    {
      "epoch": 0.7838432313537292,
      "grad_norm": 11.23480224609375,
      "learning_rate": 3.6935946144104515e-05,
      "loss": 1.2501,
      "step": 3920
    },
    {
      "epoch": 0.7858428314337133,
      "grad_norm": 8.739659309387207,
      "learning_rate": 3.6902619476104785e-05,
      "loss": 0.9989,
      "step": 3930
    },
    {
      "epoch": 0.7878424315136973,
      "grad_norm": 8.682856559753418,
      "learning_rate": 3.686929280810505e-05,
      "loss": 1.0536,
      "step": 3940
    },
    {
      "epoch": 0.7898420315936813,
      "grad_norm": 17.458547592163086,
      "learning_rate": 3.683596614010532e-05,
      "loss": 1.2393,
      "step": 3950
    },
    {
      "epoch": 0.7918416316736653,
      "grad_norm": 11.164270401000977,
      "learning_rate": 3.680263947210558e-05,
      "loss": 1.4945,
      "step": 3960
    },
    {
      "epoch": 0.7938412317536493,
      "grad_norm": 16.356037139892578,
      "learning_rate": 3.6769312804105846e-05,
      "loss": 1.2136,
      "step": 3970
    },
    {
      "epoch": 0.7958408318336333,
      "grad_norm": 8.346263885498047,
      "learning_rate": 3.6735986136106116e-05,
      "loss": 1.113,
      "step": 3980
    },
    {
      "epoch": 0.7978404319136173,
      "grad_norm": 14.635550498962402,
      "learning_rate": 3.670265946810638e-05,
      "loss": 1.3943,
      "step": 3990
    },
    {
      "epoch": 0.7998400319936013,
      "grad_norm": 14.845978736877441,
      "learning_rate": 3.666933280010665e-05,
      "loss": 0.8147,
      "step": 4000
    },
    {
      "epoch": 0.8018396320735853,
      "grad_norm": 14.854844093322754,
      "learning_rate": 3.6636006132106914e-05,
      "loss": 1.1508,
      "step": 4010
    },
    {
      "epoch": 0.8038392321535693,
      "grad_norm": 12.797466278076172,
      "learning_rate": 3.6602679464107184e-05,
      "loss": 1.3471,
      "step": 4020
    },
    {
      "epoch": 0.8058388322335532,
      "grad_norm": 9.929220199584961,
      "learning_rate": 3.656935279610745e-05,
      "loss": 1.273,
      "step": 4030
    },
    {
      "epoch": 0.8078384323135372,
      "grad_norm": 12.258395195007324,
      "learning_rate": 3.653602612810772e-05,
      "loss": 1.3169,
      "step": 4040
    },
    {
      "epoch": 0.8098380323935213,
      "grad_norm": 4.256494045257568,
      "learning_rate": 3.650269946010798e-05,
      "loss": 1.1675,
      "step": 4050
    },
    {
      "epoch": 0.8118376324735053,
      "grad_norm": 11.364853858947754,
      "learning_rate": 3.6469372792108245e-05,
      "loss": 1.276,
      "step": 4060
    },
    {
      "epoch": 0.8138372325534893,
      "grad_norm": 14.28345775604248,
      "learning_rate": 3.6436046124108515e-05,
      "loss": 0.9736,
      "step": 4070
    },
    {
      "epoch": 0.8158368326334733,
      "grad_norm": 13.391210556030273,
      "learning_rate": 3.640271945610878e-05,
      "loss": 1.276,
      "step": 4080
    },
    {
      "epoch": 0.8178364327134573,
      "grad_norm": 7.524712562561035,
      "learning_rate": 3.636939278810905e-05,
      "loss": 1.1983,
      "step": 4090
    },
    {
      "epoch": 0.8198360327934413,
      "grad_norm": 8.591636657714844,
      "learning_rate": 3.633606612010931e-05,
      "loss": 1.0727,
      "step": 4100
    },
    {
      "epoch": 0.8218356328734253,
      "grad_norm": 9.45606517791748,
      "learning_rate": 3.630273945210958e-05,
      "loss": 1.1102,
      "step": 4110
    },
    {
      "epoch": 0.8238352329534093,
      "grad_norm": 16.31220245361328,
      "learning_rate": 3.6269412784109846e-05,
      "loss": 1.1206,
      "step": 4120
    },
    {
      "epoch": 0.8258348330333933,
      "grad_norm": 8.74605655670166,
      "learning_rate": 3.623608611611011e-05,
      "loss": 1.2116,
      "step": 4130
    },
    {
      "epoch": 0.8278344331133773,
      "grad_norm": 12.346248626708984,
      "learning_rate": 3.620275944811038e-05,
      "loss": 1.0673,
      "step": 4140
    },
    {
      "epoch": 0.8298340331933614,
      "grad_norm": 12.661551475524902,
      "learning_rate": 3.616943278011064e-05,
      "loss": 1.3105,
      "step": 4150
    },
    {
      "epoch": 0.8318336332733454,
      "grad_norm": 11.918707847595215,
      "learning_rate": 3.6136106112110914e-05,
      "loss": 1.1331,
      "step": 4160
    },
    {
      "epoch": 0.8338332333533294,
      "grad_norm": 17.380149841308594,
      "learning_rate": 3.610277944411118e-05,
      "loss": 1.3181,
      "step": 4170
    },
    {
      "epoch": 0.8358328334333134,
      "grad_norm": 10.09432315826416,
      "learning_rate": 3.606945277611145e-05,
      "loss": 1.2067,
      "step": 4180
    },
    {
      "epoch": 0.8378324335132974,
      "grad_norm": 8.803640365600586,
      "learning_rate": 3.603612610811171e-05,
      "loss": 1.1309,
      "step": 4190
    },
    {
      "epoch": 0.8398320335932813,
      "grad_norm": 13.035538673400879,
      "learning_rate": 3.600279944011198e-05,
      "loss": 1.1715,
      "step": 4200
    },
    {
      "epoch": 0.8418316336732653,
      "grad_norm": 11.911402702331543,
      "learning_rate": 3.5969472772112245e-05,
      "loss": 1.5066,
      "step": 4210
    },
    {
      "epoch": 0.8438312337532493,
      "grad_norm": 16.935985565185547,
      "learning_rate": 3.593614610411251e-05,
      "loss": 1.2687,
      "step": 4220
    },
    {
      "epoch": 0.8458308338332333,
      "grad_norm": 15.074732780456543,
      "learning_rate": 3.590281943611278e-05,
      "loss": 1.168,
      "step": 4230
    },
    {
      "epoch": 0.8478304339132173,
      "grad_norm": 6.399120807647705,
      "learning_rate": 3.586949276811304e-05,
      "loss": 1.2842,
      "step": 4240
    },
    {
      "epoch": 0.8498300339932013,
      "grad_norm": 14.004207611083984,
      "learning_rate": 3.583616610011331e-05,
      "loss": 1.3401,
      "step": 4250
    },
    {
      "epoch": 0.8518296340731853,
      "grad_norm": 14.454651832580566,
      "learning_rate": 3.5802839432113576e-05,
      "loss": 1.1477,
      "step": 4260
    },
    {
      "epoch": 0.8538292341531694,
      "grad_norm": 16.35297203063965,
      "learning_rate": 3.5769512764113846e-05,
      "loss": 1.2992,
      "step": 4270
    },
    {
      "epoch": 0.8558288342331534,
      "grad_norm": 9.263208389282227,
      "learning_rate": 3.573618609611411e-05,
      "loss": 1.0686,
      "step": 4280
    },
    {
      "epoch": 0.8578284343131374,
      "grad_norm": 8.38028621673584,
      "learning_rate": 3.570285942811438e-05,
      "loss": 0.8009,
      "step": 4290
    },
    {
      "epoch": 0.8598280343931214,
      "grad_norm": 4.291645526885986,
      "learning_rate": 3.566953276011464e-05,
      "loss": 0.8402,
      "step": 4300
    },
    {
      "epoch": 0.8618276344731054,
      "grad_norm": 15.904095649719238,
      "learning_rate": 3.563620609211491e-05,
      "loss": 1.0968,
      "step": 4310
    },
    {
      "epoch": 0.8638272345530894,
      "grad_norm": 6.9572625160217285,
      "learning_rate": 3.560287942411518e-05,
      "loss": 1.2145,
      "step": 4320
    },
    {
      "epoch": 0.8658268346330734,
      "grad_norm": 12.459647178649902,
      "learning_rate": 3.556955275611544e-05,
      "loss": 0.9938,
      "step": 4330
    },
    {
      "epoch": 0.8678264347130574,
      "grad_norm": 11.682072639465332,
      "learning_rate": 3.553622608811571e-05,
      "loss": 1.0895,
      "step": 4340
    },
    {
      "epoch": 0.8698260347930414,
      "grad_norm": 14.969725608825684,
      "learning_rate": 3.5502899420115974e-05,
      "loss": 1.284,
      "step": 4350
    },
    {
      "epoch": 0.8718256348730254,
      "grad_norm": 9.82462215423584,
      "learning_rate": 3.5469572752116245e-05,
      "loss": 1.2934,
      "step": 4360
    },
    {
      "epoch": 0.8738252349530093,
      "grad_norm": 9.050975799560547,
      "learning_rate": 3.5436246084116515e-05,
      "loss": 1.1432,
      "step": 4370
    },
    {
      "epoch": 0.8758248350329934,
      "grad_norm": 10.72243881225586,
      "learning_rate": 3.540291941611678e-05,
      "loss": 1.0824,
      "step": 4380
    },
    {
      "epoch": 0.8778244351129774,
      "grad_norm": 39.329166412353516,
      "learning_rate": 3.536959274811705e-05,
      "loss": 1.3842,
      "step": 4390
    },
    {
      "epoch": 0.8798240351929614,
      "grad_norm": 8.453580856323242,
      "learning_rate": 3.533626608011731e-05,
      "loss": 1.309,
      "step": 4400
    },
    {
      "epoch": 0.8818236352729454,
      "grad_norm": 14.04312801361084,
      "learning_rate": 3.530293941211758e-05,
      "loss": 1.2582,
      "step": 4410
    },
    {
      "epoch": 0.8838232353529294,
      "grad_norm": 8.614508628845215,
      "learning_rate": 3.5269612744117846e-05,
      "loss": 1.1154,
      "step": 4420
    },
    {
      "epoch": 0.8858228354329134,
      "grad_norm": 12.570950508117676,
      "learning_rate": 3.5236286076118116e-05,
      "loss": 1.2485,
      "step": 4430
    },
    {
      "epoch": 0.8878224355128974,
      "grad_norm": 6.513674736022949,
      "learning_rate": 3.520295940811838e-05,
      "loss": 1.1752,
      "step": 4440
    },
    {
      "epoch": 0.8898220355928814,
      "grad_norm": 9.635892868041992,
      "learning_rate": 3.516963274011864e-05,
      "loss": 1.3091,
      "step": 4450
    },
    {
      "epoch": 0.8918216356728654,
      "grad_norm": 14.788000106811523,
      "learning_rate": 3.5136306072118913e-05,
      "loss": 1.3712,
      "step": 4460
    },
    {
      "epoch": 0.8938212357528494,
      "grad_norm": 14.451257705688477,
      "learning_rate": 3.510297940411918e-05,
      "loss": 1.0481,
      "step": 4470
    },
    {
      "epoch": 0.8958208358328335,
      "grad_norm": 7.513576984405518,
      "learning_rate": 3.506965273611945e-05,
      "loss": 1.2806,
      "step": 4480
    },
    {
      "epoch": 0.8978204359128175,
      "grad_norm": 9.49386978149414,
      "learning_rate": 3.503632606811971e-05,
      "loss": 1.1525,
      "step": 4490
    },
    {
      "epoch": 0.8998200359928015,
      "grad_norm": 10.454849243164062,
      "learning_rate": 3.500299940011998e-05,
      "loss": 1.0675,
      "step": 4500
    },
    {
      "epoch": 0.9018196360727855,
      "grad_norm": 13.658658981323242,
      "learning_rate": 3.4969672732120245e-05,
      "loss": 0.9555,
      "step": 4510
    },
    {
      "epoch": 0.9038192361527695,
      "grad_norm": 10.609099388122559,
      "learning_rate": 3.4936346064120515e-05,
      "loss": 1.3651,
      "step": 4520
    },
    {
      "epoch": 0.9058188362327535,
      "grad_norm": 10.870566368103027,
      "learning_rate": 3.490301939612078e-05,
      "loss": 0.9185,
      "step": 4530
    },
    {
      "epoch": 0.9078184363127374,
      "grad_norm": 11.157939910888672,
      "learning_rate": 3.486969272812104e-05,
      "loss": 1.2257,
      "step": 4540
    },
    {
      "epoch": 0.9098180363927214,
      "grad_norm": 11.493034362792969,
      "learning_rate": 3.483636606012131e-05,
      "loss": 1.3589,
      "step": 4550
    },
    {
      "epoch": 0.9118176364727054,
      "grad_norm": 13.887752532958984,
      "learning_rate": 3.4803039392121576e-05,
      "loss": 1.3894,
      "step": 4560
    },
    {
      "epoch": 0.9138172365526894,
      "grad_norm": 15.50894832611084,
      "learning_rate": 3.4769712724121846e-05,
      "loss": 1.07,
      "step": 4570
    },
    {
      "epoch": 0.9158168366326734,
      "grad_norm": 8.387073516845703,
      "learning_rate": 3.473638605612211e-05,
      "loss": 1.1459,
      "step": 4580
    },
    {
      "epoch": 0.9178164367126574,
      "grad_norm": 11.760666847229004,
      "learning_rate": 3.470305938812238e-05,
      "loss": 1.1632,
      "step": 4590
    },
    {
      "epoch": 0.9198160367926415,
      "grad_norm": 8.760969161987305,
      "learning_rate": 3.466973272012264e-05,
      "loss": 1.1117,
      "step": 4600
    },
    {
      "epoch": 0.9218156368726255,
      "grad_norm": 6.207510471343994,
      "learning_rate": 3.4636406052122913e-05,
      "loss": 1.3161,
      "step": 4610
    },
    {
      "epoch": 0.9238152369526095,
      "grad_norm": 7.408812999725342,
      "learning_rate": 3.460307938412318e-05,
      "loss": 1.0473,
      "step": 4620
    },
    {
      "epoch": 0.9258148370325935,
      "grad_norm": 4.378427505493164,
      "learning_rate": 3.456975271612344e-05,
      "loss": 1.1607,
      "step": 4630
    },
    {
      "epoch": 0.9278144371125775,
      "grad_norm": 10.167492866516113,
      "learning_rate": 3.453642604812371e-05,
      "loss": 1.2536,
      "step": 4640
    },
    {
      "epoch": 0.9298140371925615,
      "grad_norm": 14.910898208618164,
      "learning_rate": 3.4503099380123974e-05,
      "loss": 1.2916,
      "step": 4650
    },
    {
      "epoch": 0.9318136372725455,
      "grad_norm": 10.41291618347168,
      "learning_rate": 3.4469772712124244e-05,
      "loss": 1.247,
      "step": 4660
    },
    {
      "epoch": 0.9338132373525295,
      "grad_norm": 11.666461944580078,
      "learning_rate": 3.443644604412451e-05,
      "loss": 1.4462,
      "step": 4670
    },
    {
      "epoch": 0.9358128374325135,
      "grad_norm": 10.939391136169434,
      "learning_rate": 3.440311937612478e-05,
      "loss": 1.1648,
      "step": 4680
    },
    {
      "epoch": 0.9378124375124975,
      "grad_norm": 9.107660293579102,
      "learning_rate": 3.436979270812504e-05,
      "loss": 1.2819,
      "step": 4690
    },
    {
      "epoch": 0.9398120375924816,
      "grad_norm": 11.61727523803711,
      "learning_rate": 3.433646604012531e-05,
      "loss": 1.1475,
      "step": 4700
    },
    {
      "epoch": 0.9418116376724655,
      "grad_norm": 17.280546188354492,
      "learning_rate": 3.4303139372125576e-05,
      "loss": 1.2758,
      "step": 4710
    },
    {
      "epoch": 0.9438112377524495,
      "grad_norm": 12.218339920043945,
      "learning_rate": 3.426981270412584e-05,
      "loss": 1.3179,
      "step": 4720
    },
    {
      "epoch": 0.9458108378324335,
      "grad_norm": 7.429111003875732,
      "learning_rate": 3.423648603612611e-05,
      "loss": 1.1278,
      "step": 4730
    },
    {
      "epoch": 0.9478104379124175,
      "grad_norm": 6.1706624031066895,
      "learning_rate": 3.420315936812637e-05,
      "loss": 1.2153,
      "step": 4740
    },
    {
      "epoch": 0.9498100379924015,
      "grad_norm": 9.295451164245605,
      "learning_rate": 3.416983270012664e-05,
      "loss": 1.1627,
      "step": 4750
    },
    {
      "epoch": 0.9518096380723855,
      "grad_norm": 9.740483283996582,
      "learning_rate": 3.4136506032126907e-05,
      "loss": 1.3606,
      "step": 4760
    },
    {
      "epoch": 0.9538092381523695,
      "grad_norm": 6.441413879394531,
      "learning_rate": 3.410317936412718e-05,
      "loss": 1.002,
      "step": 4770
    },
    {
      "epoch": 0.9558088382323535,
      "grad_norm": 8.092058181762695,
      "learning_rate": 3.406985269612744e-05,
      "loss": 1.3924,
      "step": 4780
    },
    {
      "epoch": 0.9578084383123375,
      "grad_norm": 7.319852828979492,
      "learning_rate": 3.403652602812771e-05,
      "loss": 1.2565,
      "step": 4790
    },
    {
      "epoch": 0.9598080383923215,
      "grad_norm": 10.23288345336914,
      "learning_rate": 3.4003199360127974e-05,
      "loss": 1.3499,
      "step": 4800
    },
    {
      "epoch": 0.9618076384723055,
      "grad_norm": 20.769672393798828,
      "learning_rate": 3.396987269212824e-05,
      "loss": 1.3413,
      "step": 4810
    },
    {
      "epoch": 0.9638072385522896,
      "grad_norm": 7.018844127655029,
      "learning_rate": 3.393654602412851e-05,
      "loss": 1.2197,
      "step": 4820
    },
    {
      "epoch": 0.9658068386322736,
      "grad_norm": 7.582221508026123,
      "learning_rate": 3.390321935612877e-05,
      "loss": 1.1589,
      "step": 4830
    },
    {
      "epoch": 0.9678064387122576,
      "grad_norm": 8.07785701751709,
      "learning_rate": 3.386989268812904e-05,
      "loss": 1.0716,
      "step": 4840
    },
    {
      "epoch": 0.9698060387922416,
      "grad_norm": 9.573235511779785,
      "learning_rate": 3.3836566020129305e-05,
      "loss": 0.9411,
      "step": 4850
    },
    {
      "epoch": 0.9718056388722256,
      "grad_norm": 13.495512008666992,
      "learning_rate": 3.3803239352129576e-05,
      "loss": 1.2313,
      "step": 4860
    },
    {
      "epoch": 0.9738052389522096,
      "grad_norm": 6.523849964141846,
      "learning_rate": 3.376991268412984e-05,
      "loss": 0.9583,
      "step": 4870
    },
    {
      "epoch": 0.9758048390321936,
      "grad_norm": 8.444738388061523,
      "learning_rate": 3.373658601613011e-05,
      "loss": 1.0424,
      "step": 4880
    },
    {
      "epoch": 0.9778044391121775,
      "grad_norm": 9.013163566589355,
      "learning_rate": 3.370325934813038e-05,
      "loss": 1.1927,
      "step": 4890
    },
    {
      "epoch": 0.9798040391921615,
      "grad_norm": 14.2869234085083,
      "learning_rate": 3.366993268013064e-05,
      "loss": 1.6121,
      "step": 4900
    },
    {
      "epoch": 0.9818036392721455,
      "grad_norm": 7.120988368988037,
      "learning_rate": 3.363660601213091e-05,
      "loss": 1.3173,
      "step": 4910
    },
    {
      "epoch": 0.9838032393521295,
      "grad_norm": 17.530702590942383,
      "learning_rate": 3.360327934413118e-05,
      "loss": 1.1298,
      "step": 4920
    },
    {
      "epoch": 0.9858028394321136,
      "grad_norm": 7.3383073806762695,
      "learning_rate": 3.356995267613145e-05,
      "loss": 1.2524,
      "step": 4930
    },
    {
      "epoch": 0.9878024395120976,
      "grad_norm": 9.781767845153809,
      "learning_rate": 3.353662600813171e-05,
      "loss": 1.0125,
      "step": 4940
    },
    {
      "epoch": 0.9898020395920816,
      "grad_norm": 13.11892318725586,
      "learning_rate": 3.3503299340131974e-05,
      "loss": 0.9793,
      "step": 4950
    },
    {
      "epoch": 0.9918016396720656,
      "grad_norm": 11.650012969970703,
      "learning_rate": 3.3469972672132244e-05,
      "loss": 1.2953,
      "step": 4960
    },
    {
      "epoch": 0.9938012397520496,
      "grad_norm": 14.943472862243652,
      "learning_rate": 3.343664600413251e-05,
      "loss": 1.1491,
      "step": 4970
    },
    {
      "epoch": 0.9958008398320336,
      "grad_norm": 13.538097381591797,
      "learning_rate": 3.340331933613278e-05,
      "loss": 1.1344,
      "step": 4980
    },
    {
      "epoch": 0.9978004399120176,
      "grad_norm": 6.88840913772583,
      "learning_rate": 3.336999266813304e-05,
      "loss": 1.2435,
      "step": 4990
    },
    {
      "epoch": 0.9998000399920016,
      "grad_norm": 24.508262634277344,
      "learning_rate": 3.333666600013331e-05,
      "loss": 1.1372,
      "step": 5000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.6237752449510098,
      "eval_loss": 1.1715487241744995,
      "eval_runtime": 42.8644,
      "eval_samples_per_second": 233.34,
      "eval_steps_per_second": 29.185,
      "step": 5001
    }
  ],
  "logging_steps": 10,
  "max_steps": 15003,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2631825802948608.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
